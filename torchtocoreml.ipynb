{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abb87f08-5476-4f28-8b27-0f71d7d66fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arpandhatt/miniforge3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING:root:TensorFlow version 2.8.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.6.2 is the most recent version that has been tested.\n",
      "WARNING:root:Keras version 2.8.0 has not been tested with coremltools. You may run into unexpected errors. Keras 2.6.0 is the most recent version that has been tested.\n",
      "WARNING:root:Torch version 1.11.0 has not been tested with coremltools. You may run into unexpected errors. Torch 1.10.2 is the most recent version that has been tested.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import coremltools as ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "206da75d-e1d8-4add-9e31-beee799f8b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -----------------------------------------------------------------------------\n",
    "## Network layers\n",
    "## -----------------------------------------------------------------------------\n",
    "\n",
    "# 3x3 convolution module\n",
    "def Conv(in_channels, out_channels):\n",
    "  return nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
    "\n",
    "# ReLU function\n",
    "def relu(x):\n",
    "  return F.relu(x, inplace=True)\n",
    "\n",
    "# 2x2 max pool function\n",
    "def pool(x):\n",
    "  return F.max_pool2d(x, 2, 2)\n",
    "\n",
    "# 2x2 nearest-neighbor upsample function\n",
    "def upsample(x):\n",
    "  return F.interpolate(x, scale_factor=2, mode='nearest')\n",
    "\n",
    "# Channel concatenation function\n",
    "def concat(a, b):\n",
    "  return torch.cat((a, b), 1)\n",
    "\n",
    "## -----------------------------------------------------------------------------\n",
    "## U-Net model\n",
    "## -----------------------------------------------------------------------------\n",
    "\n",
    "class UNet(nn.Module):\n",
    "  def __init__(self, in_channels=3, out_channels=3):\n",
    "    super(UNet, self).__init__()\n",
    "\n",
    "    # Number of channels per layer\n",
    "    ic   = in_channels\n",
    "    ec1  = 32\n",
    "    ec2  = 48\n",
    "    ec3  = 64\n",
    "    ec4  = 80\n",
    "    ec5  = 96\n",
    "    dc4  = 112\n",
    "    dc3  = 96\n",
    "    dc2  = 64\n",
    "    dc1a = 64\n",
    "    dc1b = 32\n",
    "    oc   = out_channels\n",
    "\n",
    "    # Convolutions\n",
    "    self.enc_conv0  = Conv(ic,      ec1)\n",
    "    self.enc_conv1  = Conv(ec1,     ec1)\n",
    "    self.enc_conv2  = Conv(ec1,     ec2)\n",
    "    self.enc_conv3  = Conv(ec2,     ec3)\n",
    "    self.enc_conv4  = Conv(ec3,     ec4)\n",
    "    self.enc_conv5a = Conv(ec4,     ec5)\n",
    "    self.enc_conv5b = Conv(ec5,     ec5)\n",
    "    self.dec_conv4a = Conv(ec5+ec3, dc4)\n",
    "    self.dec_conv4b = Conv(dc4,     dc4)\n",
    "    self.dec_conv3a = Conv(dc4+ec2, dc3)\n",
    "    self.dec_conv3b = Conv(dc3,     dc3)\n",
    "    self.dec_conv2a = Conv(dc3+ec1, dc2)\n",
    "    self.dec_conv2b = Conv(dc2,     dc2)\n",
    "    self.dec_conv1a = Conv(dc2+ic,  dc1a)\n",
    "    self.dec_conv1b = Conv(dc1a,    dc1b)\n",
    "    self.dec_conv0  = Conv(dc1b,    oc)\n",
    "\n",
    "    # Images must be padded to multiples of the alignment\n",
    "    self.alignment = 16\n",
    "\n",
    "  def forward(self, input):\n",
    "    # Encoder\n",
    "    # -------------------------------------------\n",
    "\n",
    "    x = relu(self.enc_conv0(input))  # enc_conv0\n",
    "\n",
    "    x = relu(self.enc_conv1(x))      # enc_conv1\n",
    "    x = pool1 = pool(x)              # pool1\n",
    "\n",
    "    x = relu(self.enc_conv2(x))      # enc_conv2\n",
    "    x = pool2 = pool(x)              # pool2\n",
    "\n",
    "    x = relu(self.enc_conv3(x))      # enc_conv3\n",
    "    x = pool3 = pool(x)              # pool3\n",
    "\n",
    "    x = relu(self.enc_conv4(x))      # enc_conv4\n",
    "    x = pool(x)                      # pool4\n",
    "\n",
    "    # Bottleneck\n",
    "    x = relu(self.enc_conv5a(x))     # enc_conv5a\n",
    "    x = relu(self.enc_conv5b(x))     # enc_conv5b\n",
    "\n",
    "    # Decoder\n",
    "    # -------------------------------------------\n",
    "\n",
    "    x = upsample(x)                  # upsample4\n",
    "    x = concat(x, pool3)             # concat4\n",
    "    x = relu(self.dec_conv4a(x))     # dec_conv4a\n",
    "    x = relu(self.dec_conv4b(x))     # dec_conv4b\n",
    "\n",
    "    x = upsample(x)                  # upsample3\n",
    "    x = concat(x, pool2)             # concat3\n",
    "    x = relu(self.dec_conv3a(x))     # dec_conv3a\n",
    "    x = relu(self.dec_conv3b(x))     # dec_conv3b\n",
    "\n",
    "    x = upsample(x)                  # upsample2\n",
    "    x = concat(x, pool1)             # concat2\n",
    "    x = relu(self.dec_conv2a(x))     # dec_conv2a\n",
    "    x = relu(self.dec_conv2b(x))     # dec_conv2b\n",
    "\n",
    "    x = upsample(x)                  # upsample1\n",
    "    x = concat(x, input)             # concat1\n",
    "    x = relu(self.dec_conv1a(x))     # dec_conv1a\n",
    "    x = relu(self.dec_conv1b(x))     # dec_conv1b\n",
    "\n",
    "    x = self.dec_conv0(x)            # dec_conv0\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f66a6153-5335-4e08-9958-077980760209",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = UNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a581ec02-2b00-4a87-94ad-fac76ed2c9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input = torch.rand(1, 9, 512, 512)\n",
    "traced_model = torch.jit.trace(net, example_input)\n",
    "out = traced_model(example_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c697aa52-9d20-48da-afd2-f6c1c681d7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = ct.Shape(shape=(1, 9, ct.RangeDim(256,4096), ct.RangeDim(256,4096)))\n",
    "model_input = ct.TensorType(shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c99948e0-9d5f-4762-bed7-45c4c4e3c953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|███▉| 246/247 [00:00<00:00, 4733.78 ops/s]\n",
      "Running MIL Common passes: 100%|█████████| 34/34 [00:00<00:00, 1019.51 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 9/9 [00:00<00:00, 414.27 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|█| 191/191 [00:00<00:00, 311.63 ops/\n"
     ]
    }
   ],
   "source": [
    "model = ct.convert(\n",
    "    traced_model,\n",
    "    inputs=[model_input]\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c67bf5e-69bd-47eb-8dc4-7470c879f678",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"unet.mlmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd0f951d-c9c5-4080-8ff4-5f5237849746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coremltools.models.neural_network import flexible_shape_utils\n",
    "spec = ct.utils.load_spec('unet.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e61a4b5-f5f2-41f3-863e-5a5d75e74ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name = spec.description.input[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f61042ec-ddc8-4a9f-a9ca-ad3118b6547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flexible_shape_utils.set_multiarray_ndshape_range(spec, \n",
    "                                 feature_name=input_name, \n",
    "                                 lower_bounds=[1,3,256,256], \n",
    "                                 upper_bounds=[1,3,-1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98e1129d-265d-4af4-b94a-6ae7716f427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import tza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92cc197e-8cd4-4001-bea8-8f216df8a82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_hdr_alb_nrm = tza.Reader(\"weights/rt_ldr_calb_cnrm.tza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6b3ebfab-f1ff-4a7c-840a-02afc237f4e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32,), 'x', numpy.float32, 10432)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt_hdr_alb_nrm._table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a65815fb-25f6-4927-ac4e-2e40e1c28c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 1.2497e-02, -3.9386e-01,  1.4464e-04,  3.6471e-04, -5.2961e-01,\n",
       "        -5.7039e-01,  4.1093e-04,  1.0836e-01,  1.7407e-02, -1.4313e-02,\n",
       "         2.4525e-02,  2.9364e-02,  1.7879e-02,  1.5135e-02,  3.4147e-02,\n",
       "         6.8869e-02,  9.8098e-02,  1.9367e-01,  1.6307e-02,  1.6447e-02,\n",
       "         2.3181e-02,  6.5963e-04,  4.2232e-02,  3.1785e-02,  3.0503e-02,\n",
       "         8.6258e-04,  2.5121e-02,  9.0851e-04,  8.1616e-04,  1.2892e-02,\n",
       "         1.7959e-01,  8.9735e-02], requires_grad=True)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.get_submodule(\"enc_conv0\").bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f3223a73-23c6-44be-9ec7-f276cca0c816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.24973757e-02, -3.93858135e-01,  1.44641715e-04,  3.64705629e-04,\n",
       "        -5.29607296e-01, -5.70392549e-01,  4.10931942e-04,  1.08356625e-01,\n",
       "         1.74072701e-02, -1.43134808e-02,  2.45251376e-02,  2.93642748e-02,\n",
       "         1.78788304e-02,  1.51347220e-02,  3.41467597e-02,  6.88686296e-02,\n",
       "         9.80980322e-02,  1.93671897e-01,  1.63065661e-02,  1.64473429e-02,\n",
       "         2.31808424e-02,  6.59631507e-04,  4.22322974e-02,  3.17853317e-02,\n",
       "         3.05032786e-02,  8.62584915e-04,  2.51205117e-02,  9.08514368e-04,\n",
       "         8.16164771e-04,  1.28915962e-02,  1.79587409e-01,  8.97354633e-02],\n",
       "       dtype=float32),\n",
       " 'x')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt_hdr_alb_nrm[\"enc_conv0.bias\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "813b2ed7-5c32-4b07-8858-cac8cec4d4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.get_submodule(\"enc_conv0\").bias = torch.nn.Parameter(torch.tensor(rt_hdr_alb_nrm[\"enc_conv0.bias\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "24d00530-0836-45ab-9e8e-14ff3ce188d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from training import tza\n",
    "\n",
    "def reload_unet(filepath: str) -> nn.Module:\n",
    "    data = tza.Reader(filepath)\n",
    "    in_channels = data[\"enc_conv0.weight\"][0].shape[1]\n",
    "    out_channels = data[\"dec_conv0.weight\"][0].shape[0]\n",
    "    net = UNet(in_channels, out_channels)\n",
    "    for key in data._table.keys():\n",
    "        layer, param = key.split(\".\")\n",
    "        submodule = net.get_submodule(layer)\n",
    "        if param == \"weight\":\n",
    "            submodule.weight = torch.nn.Parameter(torch.tensor(data[key][0]))\n",
    "        else:\n",
    "            submodule.bias = torch.nn.Parameter(torch.tensor(data[key][0]))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "df817cce-fc62-4df5-b471-5831c1ff8ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = reload_unet(\"weights/rt_hdr_calb_cnrm.tza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "1e6478b1-59a8-4009-80a7-da15cfad87de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import coremltools as ct\n",
    "import torch\n",
    "\n",
    "def save_to_mlmodel(filepath: str, net: nn.Module):\n",
    "    in_channels = net.enc_conv0.weight.shape[1]\n",
    "    example_input = torch.rand(1, in_channels, 512, 512)\n",
    "    traced_model = torch.jit.trace(net, example_input)\n",
    "    out = traced_model(example_input)\n",
    "    \n",
    "    input_shape = ct.Shape(shape=(1, in_channels, ct.RangeDim(256,4096), ct.RangeDim(256,4096)))\n",
    "    model_input = ct.TensorType(shape=input_shape)\n",
    "    \n",
    "    model = ct.convert(\n",
    "        traced_model,\n",
    "        inputs=[model_input]\n",
    "     )\n",
    "    \n",
    "    model.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "79ec64b8-d4f5-40c3-8e86-26f13312ef3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|████████████████████████████████████████████▊| 246/247 [00:00<00:00, 4783.22 ops/s]\n",
      "Running MIL Common passes: 100%|███████████████████████████████████████████████████| 34/34 [00:00<00:00, 972.04 passes/s]\n",
      "Running MIL Clean up passes: 100%|███████████████████████████████████████████████████| 9/9 [00:00<00:00, 412.90 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|████████████████████████████████████████| 191/191 [00:00<00:00, 314.50 ops/s]\n"
     ]
    }
   ],
   "source": [
    "save_to_mlmodel(\"rt_hdr_calb_cnrm.mlmodel\", net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "36674733-fbce-4762-880e-ca4566d9ecfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGELOG.md                    \u001b[1m\u001b[36mmkl-dnn\u001b[m\u001b[m\n",
      "CMakeLists.txt                  readme.pdf\n",
      "LICENSE.txt                     requirements.txt\n",
      "README.md                       \u001b[1m\u001b[36mscripts\u001b[m\u001b[m\n",
      "SECURITY.md                     third-party-programs-oneDNN.txt\n",
      "\u001b[1m\u001b[36mapps\u001b[m\u001b[m                            third-party-programs-oneTBB.txt\n",
      "\u001b[1m\u001b[36mcmake\u001b[m\u001b[m                           third-party-programs.txt\n",
      "\u001b[1m\u001b[36mcmake-build-debug\u001b[m\u001b[m               torchtocoreml.ipynb\n",
      "\u001b[1m\u001b[36mcommon\u001b[m\u001b[m                          \u001b[1m\u001b[36mtraining\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mcore\u001b[m\u001b[m                            unet.mlmodel\n",
      "\u001b[1m\u001b[36mdoc\u001b[m\u001b[m                             \u001b[1m\u001b[36mweights\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36minclude\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7821b2fd-8ea2-4b0f-961a-02dc3830f161",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
